{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1z-E7187meM"
   },
   "outputs": [],
   "source": [
    "import xmltodict, json, os, re, sys\n",
    "import http.client, urllib.parse, uuid\n",
    "import numpy as np\n",
    "from googletrans import Translator\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/vvs/Documents/Telegram clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(id, filename_prefix):\n",
    "#     print(filename_prefix)\n",
    "    \n",
    "    f_annotation = open(\"%s.aa\" % filename_prefix)\n",
    "    annotations = xmltodict.parse(''.join(f_annotation.readlines()))[\"annotations\"]\n",
    "    units = annotations[\"unit\"]\n",
    "    if not 'relation' in annotations:\n",
    "        relations = []\n",
    "    else:\n",
    "        relations = annotations[\"relation\"]\n",
    "    schema = annotations[\"schema\"] if 'schema' in annotations else []\n",
    "\n",
    "    f_discourse = open(\"%s.ac\" % filename_prefix)\n",
    "    discourse = f_discourse.readline()\n",
    "    for i in range(len(discourse)):\n",
    "        if ord(discourse[i]) >= 128: discourse = discourse[:i] + \" \" + discourse[i+1:]\n",
    "    \n",
    "    edus, buf_dialogues = {}, {}\n",
    "    \n",
    "    for item in units:\n",
    "        _id = item[\"@id\"]\n",
    "        start = int(item[\"positioning\"][\"start\"][\"singlePosition\"][\"@index\"])\n",
    "        end = int(item[\"positioning\"][\"end\"][\"singlePosition\"][\"@index\"])\n",
    "        _type = item[\"characterisation\"][\"type\"]\n",
    "        if _type in [\"Turn\", \"NonplayerTurn\"]: continue\n",
    "        elif _type == \"Dialogue\":\n",
    "            buf_dialogues[_id] = {\n",
    "                \"start\": start,\n",
    "                \"end\": end,\n",
    "                \"edus\": {},\n",
    "                \"cdus\": {},\n",
    "                \"relations\": []\n",
    "            }\n",
    "        else:\n",
    "            edus[_id] = {\n",
    "                \"id\": _id,\n",
    "                \"type\": _type,\n",
    "                \"text\": discourse[start:end],\n",
    "                \"start\": start,\n",
    "                \"end\": end\n",
    "            }\n",
    "\n",
    "    belong_to = {}\n",
    "    for id_edu in edus:\n",
    "        edu = edus[id_edu]\n",
    "        found = False\n",
    "        for id_dialogue in buf_dialogues:\n",
    "            dialog = buf_dialogues[id_dialogue]\n",
    "            if dialog[\"start\"] <= edu[\"start\"] and dialog[\"end\"] >= edu[\"end\"]:\n",
    "                found = True\n",
    "                dialog[\"edus\"][id_edu] = edu\n",
    "                belong_to[id_edu] = id_dialogue\n",
    "                break\n",
    "        if not found:\n",
    "            raise Warning(\"Dialogue not found\")\n",
    "    \n",
    "    if type(schema) != list: schema = [schema] \n",
    "    for item in schema:\n",
    "        _id = item[\"@id\"]\n",
    "        _type = item[\"characterisation\"][\"type\"]\n",
    "        if item[\"positioning\"] == None: continue\n",
    "        \n",
    "        cdu = []\n",
    "        if \"embedded-unit\" in item[\"positioning\"]:\n",
    "            if type(item[\"positioning\"][\"embedded-unit\"]) == list:\n",
    "                cdu = [unit[\"@id\"] for unit in item[\"positioning\"][\"embedded-unit\"]]\n",
    "            else:\n",
    "                cdu = [item[\"positioning\"][\"embedded-unit\"][\"@id\"]]\n",
    "            for edu in cdu:\n",
    "                if not edu in edus:\n",
    "                    cdu.remove(edu)\n",
    "        if \"embedded-schema\" in item[\"positioning\"]:\n",
    "            if type(item[\"positioning\"][\"embedded-schema\"]) == list:\n",
    "                cdu += [unit[\"@id\"] for unit in item[\"positioning\"][\"embedded-schema\"]]\n",
    "            else:\n",
    "                cdu += [item[\"positioning\"][\"embedded-schema\"][\"@id\"]]\n",
    "        belong_to[_id] = belong_to[cdu[0]]\n",
    "        buf_dialogues[belong_to[_id]][\"cdus\"][_id] = cdu\n",
    "        \n",
    "    if type(relations) != list: relations = [relations]\n",
    "    for item in relations:\n",
    "        _id = item[\"@id\"]\n",
    "        x = item[\"positioning\"][\"term\"][0][\"@id\"]\n",
    "        y = item[\"positioning\"][\"term\"][1][\"@id\"]\n",
    "        _type = item[\"characterisation\"][\"type\"]\n",
    "        buf_dialogues[belong_to[x]][\"relations\"].append({\n",
    "            \"type\": _type,\n",
    "            \"x\": x,\n",
    "            \"y\": y\n",
    "        })\n",
    "    dialogues = []\n",
    "    for _id in buf_dialogues:\n",
    "        buf_dialogues[_id][\"id\"] = id\n",
    "        dialogues.append(buf_dialogues[_id])\n",
    "    return dialogues\n",
    "        \n",
    "def process_dialogue(dialogue):\n",
    "    has_incoming = {}\n",
    "    \n",
    "    for relation in dialogue[\"relations\"]:\n",
    "        has_incoming[relation[\"y\"]] = True\n",
    "       \n",
    "    for _id in dialogue[\"edus\"]:\n",
    "        edu = dialogue[\"edus\"][_id]\n",
    "        if edu[\"type\"] == \"paragraph\": continue\n",
    "        \n",
    "        for _id_para in dialogue[\"edus\"]:\n",
    "            def parse_speaker(text):\n",
    "                return (text.split())[2]\n",
    "            \n",
    "            para = dialogue[\"edus\"][_id_para]\n",
    "            if para[\"type\"] != \"paragraph\": continue\n",
    "            if para[\"start\"] <= edu[\"start\"] and para[\"end\"] >= edu[\"end\"]:\n",
    "                edu[\"speaker\"] = parse_speaker(para[\"text\"])\n",
    "    \n",
    "    idx = {}\n",
    "    dialogue[\"edu_list\"] = []\n",
    "    \n",
    "    for _id in dialogue[\"edus\"]:\n",
    "        if dialogue[\"edus\"][_id][\"type\"] != \"paragraph\":\n",
    "            dialogue[\"edu_list\"].append(dialogue[\"edus\"][_id])\n",
    "    dialogue[\"edu_list\"] = sorted(dialogue[\"edu_list\"], key=lambda edu: edu[\"start\"])\n",
    "    \n",
    "    for i in range(len(dialogue[\"edu_list\"])):\n",
    "        edu = dialogue[\"edu_list\"][i]\n",
    "        idx[edu[\"id\"]] = i\n",
    "        \n",
    "#     for i, edu in enumerate(dialogue[\"edu_list\"]):\n",
    "#         print(i, edu[\"speaker\"], \":\", edu[\"text\"])\n",
    "       \n",
    "#     print(\"===\")\n",
    "\n",
    "    for relation in dialogue[\"relations\"]:\n",
    "        def get_head(x):\n",
    "            if x in dialogue[\"edus\"]: return x\n",
    "            else: \n",
    "                for du in dialogue[\"cdus\"][x]:\n",
    "                    if not du in has_incoming: return get_head(du)\n",
    "                raise Warning(\"Can't find the recursive head\")\n",
    "            \n",
    "        relation[\"x\"] = idx[get_head(relation[\"x\"])]\n",
    "        relation[\"y\"] = idx[get_head(relation[\"y\"])]\n",
    "        \n",
    "    dialogue_cleaned = {\n",
    "        \"id\": dialogue[\"id\"],\n",
    "        \"edus\": [],\n",
    "        \"relations\": []\n",
    "    }\n",
    "    \n",
    "    for edu in dialogue[\"edu_list\"]:\n",
    "        dialogue_cleaned[\"edus\"].append({\n",
    "            \"speaker\": edu[\"speaker\"],\n",
    "            \"text\": edu[\"text\"]\n",
    "        })\n",
    "    for relation in dialogue[\"relations\"]:\n",
    "        dialogue_cleaned[\"relations\"].append({\n",
    "            \"type\": relation[\"type\"],\n",
    "            \"x\": relation[\"x\"],\n",
    "            \"y\": relation[\"y\"]\n",
    "        })\n",
    "        \n",
    "    return dialogue_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dialogues(imput_dir, output = None,return_dialog = False):\n",
    "    dialogues = []\n",
    "    dirs = os.listdir(imput_dir)\n",
    "\n",
    "    for directory in dirs:\n",
    "        dirs2 = os.listdir(f'{imput_dir}/{directory}')\n",
    "        for directory2 in dirs2:\n",
    "            tmp_path = f'{imput_dir}{directory}/{directory2}/'\n",
    "            path = os.path.join(tmp_path, \"discourse/GOLD\")\n",
    "            if os.path.exists(path):\n",
    "                for filename in os.listdir(path):\n",
    "                    if re.match(\"\\S*.ac\", filename):\n",
    "                        _id = filename[:filename.find('_')]\n",
    "                        dialogues += process_file(_id, os.path.join(path, filename[:filename.index(\".\")]))\n",
    "     \n",
    "    dialogues_cleaned = []\n",
    "    for dialogue in dialogues:\n",
    "        dialog = process_dialogue(dialogue)\n",
    "        dialogues_cleaned.append(dialog)\n",
    "    if output != None:\n",
    "        fout = open(output, \"w\")\n",
    "        fout.write(json.dumps(dialogues_cleaned))\n",
    "        fout.close()\n",
    "    print(\"%d dialogues\" % len(dialogues_cleaned))\n",
    "    if return_dialog:\n",
    "        return dialogues_cleaned\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ru_translate(txt, attempt = 50, sourse_ln = 'en', destination_ln = 'ru', pause = None):\n",
    "    try:\n",
    "        translator = Translator()\n",
    "        eng_word = re.compile(r'[\\w]{2,}')\n",
    "        output = translator.translate(txt,src=sourse_ln, dest= destination_ln).text\n",
    "        counter = 0\n",
    "        if eng_word.match(output):\n",
    "            while translator.translate(output).src ==sourse_ln:\n",
    "                output = translator.translate(output, src = sourse_ln, dest = destination_ln).text\n",
    "                counter += 1\n",
    "                if counter > attempt:\n",
    "                    return output\n",
    "        return output\n",
    "    except:\n",
    "        if pause == None:\n",
    "            time.sleep(5)\n",
    "            print(f'waiting 5 sec,  text:{txt}')\n",
    "            pause = 60\n",
    "        elif pause ==60:\n",
    "            time.sleep(60)\n",
    "            print(f'waiting 60 sec,  text:{txt}')\n",
    "            pause = 120\n",
    "        elif pause ==120:\n",
    "            time.sleep(120)\n",
    "            print(f'waiting 120 sec,  text:{txt}')\n",
    "            pause = 555\n",
    "        else:\n",
    "            print(f'return {txt}')\n",
    "            return txt\n",
    "        output = ru_translate(txt, \n",
    "                              attempt = attempt, \n",
    "                              sourse_ln = sourse_ln, \n",
    "                              destination_ln = destination_ln, \n",
    "                              pause = pause)\n",
    "        return output\n",
    "            \n",
    "\n",
    "def dialog_translator(dialog, \n",
    "                      saving_file = None, \n",
    "                      srs_ln = 'en', \n",
    "                      dest_ln = 'ru', \n",
    "                      translation_attempt = 50,\n",
    "                      return_dialog = False):\n",
    "    \n",
    "    dialogues_test_cleaned_tr = []\n",
    "    \n",
    "    for index_game, game_test in enumerate(dialog):  \n",
    "        dialogues_test_cleaned_tr.append(game_test)\n",
    "        for index_fraze, fraze in enumerate(game_test['edus']):\n",
    "            output = ru_translate(fraze['text'], translation_attempt, srs_ln, dest_ln)\n",
    "            dialogues_test_cleaned_tr[index_game]['edus'][index_fraze]['text'] = output\n",
    "            \n",
    "    if saving_file != None:\n",
    "        print('print json...')\n",
    "        fout = open(saving_file, \"w\", encoding='utf-8')\n",
    "        fout.write(json.dumps(dialogues_test_cleaned_tr,ensure_ascii=False,))\n",
    "        fout.close()\n",
    "        \n",
    "    print(\"%d dialogues translated\" % len(dialogues_test_cleaned_tr))\n",
    "    if return_dialog:\n",
    "        return dialogues_test_cleaned_tr\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1086 dialogues\n",
      "waiting 5 sec,  text:But it's not imperative.\n",
      "print json...\n",
      "1086 dialogues translated\n"
     ]
    }
   ],
   "source": [
    "input_dir_train = './data/external/chinadataset/train/data/'\n",
    "output_file_train = './data/processed/chinadataset/train_spect.json'\n",
    "output_file_train_ru = './data/processed/chinadataset/train_spect_ru.json'\n",
    "dialogues_cleaned_train = clean_dialogues(imput_dir = input_dir_train,  output = output_file_train, return_dialog = True)\n",
    "dialogues_cleaned_train_ru = dialog_translator(dialog = dialogues_cleaned_train,\n",
    "                                               saving_file = output_file_train_ru,\n",
    "                                               return_dialog = True\n",
    "                                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 dialogues\n",
      "print json...\n",
      "111 dialogues translated\n"
     ]
    }
   ],
   "source": [
    "input_dir_test = './data/external/chinadataset/TEST_spect-stac-linguistic-2018-03-21/'\n",
    "output_file_test = './data/processed/chinadataset/new_test_spect.json'\n",
    "output_file_test_ru = './data/processed/chinadataset/new_test_spect_ru.json'\n",
    "\n",
    "dialogues_cleaned_test = clean_dialogues(imput_dir =input_dir_test, \n",
    "                                         output = output_file_test, \n",
    "                                         return_dialog = True)\n",
    "dialogues_cleaned_test_ru = dialog_translator(dialog = dialogues_cleaned_test,\n",
    "                                         saving_file = output_file_test_ru,\n",
    "                                         return_dialog = True\n",
    "                                        )\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNzRXhgCfoTDP1psNYVkmJj",
   "name": "Лекция 2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
